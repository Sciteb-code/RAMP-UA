{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis with the OpenCL RAMP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import opencl modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import yaml # pyyaml library for reading the parameters.yml file\n",
    "import os\n",
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from microsim.opencl.ramp.run import run_headless\n",
    "from microsim.opencl.ramp.snapshot_convertor import SnapshotConvertor\n",
    "from microsim.opencl.ramp.snapshot import Snapshot\n",
    "from microsim.opencl.ramp.params import Params, IndividualHazardMultipliers, LocationHazardMultipliers\n",
    "from microsim.opencl.ramp.simulator import Simulator\n",
    "from microsim.opencl.ramp.disease_statuses import DiseaseStatus\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from experiments_functions import Functions # Some additional notebook-specific functions required (functions.py)\n",
    "\n",
    "# Useful for connecting to this kernel\n",
    "#%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup params for all runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the parameters file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS_FILENAME = \"default.yml\"\n",
    "with open(os.path.join(\"../../\",\"model_parameters\", PARAMETERS_FILENAME)) as f:\n",
    "    parameters = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    \n",
    "sim_params = parameters[\"microsim\"]  # Parameters for the dynamic microsim (python)\n",
    "calibration_params = parameters[\"microsim_calibration\"]\n",
    "disease_params = parameters[\"disease\"]  # Parameters for the disease model (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the parameters for the OpenCL model. (See [main.py](https://github.com/Urban-Analytics/RAMP-UA/blob/052861cc51be5bc1827c85bb827209f0df73c685/microsim/main.py#L262) for an example of how this is done in the code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_risk_beta = disease_params['current_risk_beta']\n",
    "\n",
    "# The OpenCL model incorporates the current risk beta by pre-multiplying the hazard multipliers with it\n",
    "location_hazard_multipliers = LocationHazardMultipliers(\n",
    "    retail=calibration_params[\"hazard_location_multipliers\"][\"Retail\"] * current_risk_beta,\n",
    "    primary_school=calibration_params[\"hazard_location_multipliers\"][\"PrimarySchool\"] * current_risk_beta,\n",
    "    secondary_school=calibration_params[\"hazard_location_multipliers\"][\"SecondarySchool\"] * current_risk_beta,\n",
    "    home=calibration_params[\"hazard_location_multipliers\"][\"Home\"] * current_risk_beta,\n",
    "    work=calibration_params[\"hazard_location_multipliers\"][\"Work\"] * current_risk_beta,\n",
    ")\n",
    "\n",
    "# Individual hazard multipliers can be passed straight through\n",
    "individual_hazard_multipliers = IndividualHazardMultipliers(\n",
    "    presymptomatic=calibration_params[\"hazard_individual_multipliers\"][\"presymptomatic\"],\n",
    "    asymptomatic=calibration_params[\"hazard_individual_multipliers\"][\"asymptomatic\"],\n",
    "    symptomatic=calibration_params[\"hazard_individual_multipliers\"][\"symptomatic\"]\n",
    ")\n",
    "\n",
    "proportion_asymptomatic = disease_params[\"asymp_rate\"]\n",
    "\n",
    "params = Params(\n",
    "    location_hazard_multipliers=location_hazard_multipliers,\n",
    "    individual_hazard_multipliers=individual_hazard_multipliers,\n",
    "    proportion_asymptomatic=proportion_asymptomatic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snapshot path\n",
    "**NB** this is the path to the OpenCL snapshot file generated by running `microsim/main.py`. To run with new population data just re-run `main.py --opencl` without the `--use-cache` option, so that it regenerates a new snapshot file and writes it to this location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencl_dir = \"../../microsim/opencl\"\n",
    "snapshot_filepath = os.path.join(opencl_dir, \"snapshots\", \"cache.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run OpenCL simulation for multiple repetitions\n",
    "\n",
    "This shows what happens with the 'default' (manually calibrated) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 120\n",
    "repetitions = 10\n",
    "num_seed_days = 10\n",
    "use_gpu=False\n",
    "\n",
    "summaries = []\n",
    "final_results = []\n",
    "# Prepare the function arguments as lists for starmap\n",
    "l_i = [i for i in range(repetitions)]\n",
    "l_iterations = [iterations] * repetitions\n",
    "l_snapshot_filepath = [snapshot_filepath] * repetitions\n",
    "l_params = [params] * repetitions\n",
    "l_opencl_dir = [opencl_dir] * repetitions\n",
    "l_num_seed_days = [num_seed_days] * repetitions\n",
    "l_use_gpu = [use_gpu] * repetitions\n",
    "l_store_detailed_counts= [True] * repetitions  # If False then model is much quicker but no age breakdown\n",
    "\n",
    "#results = functions.run_opencl_model_multiprocess(\n",
    "#    l_i, l_iterations, l_snapshot_filepath, l_params, l_opencl_dir, l_num_seed_days, l_use_gpu)\n",
    "\n",
    "import itertools  # (only while I can't get multiprocessing to work)\n",
    "try:\n",
    "    with mp.Pool(processes=int(os.cpu_count())) as pool:\n",
    "        #results = pool.starmap(\n",
    "        results = itertools.starmap(\n",
    "            functions._run_opencl_model, zip(\n",
    "                l_i, l_iterations, l_snapshot_filepath, l_params, l_opencl_dir, l_num_seed_days, l_use_gpu, l_store_detailed_counts\n",
    "        ))\n",
    "finally:  # Make sure they get closed (shouldn't be necessary)\n",
    "    pool.close()\n",
    "\n",
    "summaries = [x[0] for x in results]\n",
    "final_results = [x[1] for x in results]\n",
    "\n",
    "# Conver the summaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot output summary data\n",
    "\n",
    "### Total counts of disease status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summaries(summaries, plot_type=\"error_bars\"):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,7))\n",
    "    \n",
    "    # Work out the number of repetitions and iterations\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "\n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "        if disease_status==DiseaseStatus.Susceptible or disease_status==DiseaseStatus.Recovered:\n",
    "            continue\n",
    "        # Calculate the mean and standard deviation\n",
    "        matrix = np.zeros(shape=(reps,iters))\n",
    "        for rep in range(reps):\n",
    "            matrix[rep] = summaries[rep].total_counts[d]\n",
    "        mean = np.mean(matrix, axis=0)\n",
    "        sd = np.std(matrix, axis=0)\n",
    "        if plot_type == \"error_bars\":\n",
    "            ax.errorbar(x, mean, sd, label=f\"{disease_status}\" )\n",
    "        elif plot_type == \"lines\":\n",
    "            for rep in range(reps):\n",
    "                ax.plot(x, matrix[rep], label=f\"{disease_status} {rep}\", \n",
    "                        color=plt.cm.get_cmap(\"hsv\", len(DiseaseStatus))(d) )\n",
    "                \n",
    "    ax.legend() \n",
    "    ax.set_title(\"Disease Status\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Number of cases\")\n",
    "\n",
    "def _get_iters_and_reps(summaries):\n",
    "    reps = len(summaries)\n",
    "    iters = len(summaries[0].total_counts[0])\n",
    "    return (iters, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summaries(summaries=summaries, plot_type=\"error_bars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_summaries(summaries=summaries, plot_type=\"lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease statuses by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def plot_disease_status_by_age(summaries):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(int(len(DiseaseStatus)/2), int(len(DiseaseStatus)/2), \n",
    "                           figsize=(15,11), tight_layout=True)\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "    age_thresholds = summaries[0].age_thresholds\n",
    "\n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "        lower_age_bound = 0\n",
    "        for age_idx in range(len(age_thresholds)):\n",
    "            matrix = np.zeros(shape=(reps, iters))\n",
    "            for rep in range(reps):\n",
    "                #matrix[age_idx][rep][it] = summaries[rep].age_counts[str(disease_status)][age_idx][it]\n",
    "                matrix[rep] = summaries[rep].age_counts[str(disease_status)][age_idx]\n",
    "            mean = np.mean(matrix, axis=0)\n",
    "            sd = np.std(matrix, axis=0)\n",
    "            ax.flat[d].errorbar(x, mean, sd, label=f\"{lower_age_bound} - {age_thresholds[age_idx]}\" )\n",
    "            lower_age_bound = age_thresholds[age_idx]\n",
    "                \n",
    "            ax.flat[d].legend() \n",
    "            ax.flat[d].set_title(f\"{str(disease_status)}\")\n",
    "            ax.flat[d].set_xlabel(\"Iteration\")\n",
    "            ax.flat[d].set_ylabel(\"Number of cases\")\n",
    "    #fig.set_title(f\"Num {disease_status} people by age group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disease_status_by_age(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSOA geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MSOA shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsim.load_msoa_locations import load_osm_shapefile, load_msoa_shapes\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = (\"../devon_data\")\n",
    "\n",
    "osm_buildings = load_osm_shapefile(data_dir)\n",
    "\n",
    "devon_msoa_shapes = load_msoa_shapes(data_dir, visualize=False)\n",
    "\n",
    "devon_msoa_shapes.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_msoa_choropleth(msoa_shapes, summary, disease_status, timestep):\n",
    "    # get dataframes for all statuses\n",
    "    msoa_data = summary.get_area_dataframes()\n",
    "    \n",
    "    msoa_data_for_status = msoa_data[disease_status]\n",
    "\n",
    "    # add \"Code\" column so dataframes can be merged\n",
    "    msoa_data_for_status[\"Code\"] = msoa_data_for_status.index\n",
    "    msoa_shapes = pd.merge(msoa_shapes, msoa_data_for_status, on=\"Code\")\n",
    "\n",
    "    msoa_shapes.plot(column=f\"Day{timestep}\", legend=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot disease status by MSOA for a given timestep and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_status = \"exposed\"\n",
    "\n",
    "plot_msoa_choropleth(devon_msoa_shapes, summaries[0], disease_status, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Data\n",
    "\n",
    "Read the real observations (number of hospital admissions in Devon) that will be used to calibrate the model. See the [README](./observation_data/README.md) for information about how these observations were obtained. They aren't the raw cases, it's actually a model that was fitted to the lagged cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Cases\n",
       "0      1     10\n",
       "1      2     11\n",
       "2      3     13\n",
       "3      4     16\n",
       "4      5     18\n",
       "..   ...    ...\n",
       "98    99     10\n",
       "99   100      9\n",
       "100  101      9\n",
       "101  102      8\n",
       "102  103      8\n",
       "\n",
       "[103 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = pd.read_csv(\"observation_data/gam_cases.csv\", header=0, names=[\"Day\", \"Cases\"], )\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error: Fitness Function\n",
    "\n",
    "To calibrate the model we need a fitness function that tells us, for a given result, how similar it is to the observations. There are lots of ways to do this. For now, just take the **Euclidean distance (L2 norm)** between the observed number of cases and the simulated number of cases.\n",
    "\n",
    "Note that the model is seeded using the first few days of cases, so at the beginning of a run the simulated data will be identical to the observations. This doesn't matter though because the relative difference between different parameter combinations will be the same regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fitness function is defined in functions.py (so that it can be tested)\n",
    "fit = Functions.fit_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit([1,1,1], [1,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Parameters\n",
    "\n",
    "Which parameters will we try to calibrate on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXXX decide which parameters to calibrate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calibration Method: XXXX\n",
    "\n",
    "Simulated annealing? Latin-Hypercube sampling? GA? ABC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Tests\n",
    "\n",
    "I've not put tests into a notebook before. Not sure how well this will work. Uses a small ipython extension: https://github.com/akaihola/ipython_pytest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
